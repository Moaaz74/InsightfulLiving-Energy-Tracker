{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "779b73ed",
   "metadata": {},
   "source": [
    "# Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9005ec78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "from kafka import KafkaProducer, KafkaConsumer\n",
    "from cassandra.cluster import Cluster\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "import schedule\n",
    "import time\n",
    "import base64\n",
    "import io\n",
    "import requests\n",
    "from keras.applications.vgg16 import VGG16  # Assuming you want to use Keras VGG16\n",
    "from cassandra.util import uuid_from_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67f458b",
   "metadata": {},
   "source": [
    "# configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8944e534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kafka configuration\n",
    "bootstrap_servers = 'localhost:9092'\n",
    "input_topic = 'photo-topic'\n",
    "#output_topic = 'output_topicc'\n",
    "\n",
    "# Cassandra configuration\n",
    "cassandra_host = 'localhost'\n",
    "cassandra_keyspace = 'big_data'#................................................................\n",
    "cassandra_table = 'photo'\n",
    "\n",
    "# Connect to Kafka\n",
    "consumer = KafkaConsumer(bootstrap_servers=bootstrap_servers)\n",
    "consumer.subscribe([input_topic])\n",
    "\n",
    "# Kafka producer\n",
    "#producer = KafkaProducer(bootstrap_servers=bootstrap_servers)\n",
    "\n",
    "\n",
    "# Load the saved model\n",
    "save_model = tf.keras.models.load_model('my_keras_model.h5')#.....................\n",
    "class_names = ['fire_images', 'non_fire_images']\n",
    "#image_folder = r\"C:\\Users\\AL-FAJR\\Desktop\\Last_GP\\FIRE-SMOKE-DATASET\\Test\\Neutral\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed2eb11",
   "metadata": {},
   "source": [
    "# Cassandra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f73370f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<cassandra.cluster.ResultSet at 0x222708f9e10>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Connect to Cassandra\n",
    "cluster = Cluster([cassandra_host])\n",
    "session = cluster.connect()\n",
    "#session.execute(f\"CREATE KEYSPACE IF NOT EXISTS {cassandra_keyspace} WITH REPLICATION = {{ 'class' : 'SimpleStrategy', 'replication_factor' : 1 }}\")\n",
    "session.set_keyspace(cassandra_keyspace)\n",
    "session.execute(f\"CREATE TABLE IF NOT EXISTS {cassandra_table} (id UUID  ,homeId TEXT, roomId TEXT, class_name TEXT , image_Path TEXT , DateTime TIMESTAMP, PRIMARY KEY (roomId,DateTime,id) )\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f60aa2",
   "metadata": {},
   "source": [
    "# Kafka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2462d91",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received message: b'{\"HomeId\" : \"268\" , \"RoomId\" : \"2471\" , \"DateTime\": \"2024-02-12 03:30:14\" , \"ImagePath\" : \"C:\\\\\\\\Users\\\\\\\\Moataz Nasr\\\\\\\\Downloads\\\\\\\\images\\\\\\\\image_26.jpg\"}'\n",
      "C:\\Users\\Moataz Nasr\\Downloads\\images\\image_26.jpg\n",
      "1/1 [==============================] - 1s 662ms/step\n",
      "Processed message: {'HomeId': '268', 'RoomId': '2471', 'DateTime': '2024-02-12 03:30:14', 'ImagePath': 'C:\\\\Users\\\\Moataz Nasr\\\\Downloads\\\\images\\\\image_26.jpg', 'probability': 4.374553423821279e-28, 'class_name': 'fire_images'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Moataz Nasr\\AppData\\Local\\Temp\\ipykernel_29284\\4174358698.py:35: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  probability = float(prediction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received message: b'{\"HomeId\" : \"268\" , \"RoomId\" : \"2471\" , \"DateTime\": \"2024-02-12 03:31:02\" , \"ImagePath\" : \"C:\\\\\\\\Users\\\\\\\\Moataz Nasr\\\\\\\\Downloads\\\\\\\\images\\\\\\\\image_439.jpg\"}'\n",
      "C:\\Users\\Moataz Nasr\\Downloads\\images\\image_439.jpg\n",
      "1/1 [==============================] - 0s 233ms/step\n",
      "Processed message: {'HomeId': '268', 'RoomId': '2471', 'DateTime': '2024-02-12 03:31:02', 'ImagePath': 'C:\\\\Users\\\\Moataz Nasr\\\\Downloads\\\\images\\\\image_439.jpg', 'probability': 4.420784710097876e-29, 'class_name': 'fire_images'}\n",
      "Received message: b'{\"HomeId\" : \"268\" , \"RoomId\" : \"2471\" , \"DateTime\": \"2024-02-12 03:31:26\" , \"ImagePath\" : \"C:\\\\\\\\Users\\\\\\\\Moataz Nasr\\\\\\\\Downloads\\\\\\\\images\\\\\\\\image_530.jpg\"}'\n",
      "C:\\Users\\Moataz Nasr\\Downloads\\images\\image_530.jpg\n",
      "1/1 [==============================] - 0s 263ms/step\n",
      "Processed message: {'HomeId': '268', 'RoomId': '2471', 'DateTime': '2024-02-12 03:31:26', 'ImagePath': 'C:\\\\Users\\\\Moataz Nasr\\\\Downloads\\\\images\\\\image_530.jpg', 'probability': 0.0, 'class_name': 'fire_images'}\n",
      "Received message: b'{\"HomeId\" : \"268\" , \"RoomId\" : \"2471\" , \"DateTime\": \"2024-02-12 03:34:45\" , \"ImagePath\" : \"C:\\\\\\\\Users\\\\\\\\Moataz Nasr\\\\\\\\Downloads\\\\\\\\images\\\\\\\\image_1.jpg\"}'\n",
      "C:\\Users\\Moataz Nasr\\Downloads\\images\\image_1.jpg\n",
      "1/1 [==============================] - 0s 203ms/step\n",
      "Processed message: {'HomeId': '268', 'RoomId': '2471', 'DateTime': '2024-02-12 03:34:45', 'ImagePath': 'C:\\\\Users\\\\Moataz Nasr\\\\Downloads\\\\images\\\\image_1.jpg', 'probability': 1.0, 'class_name': 'non_fire_images'}\n",
      "Received message: b'{\"HomeId\" : \"268\" , \"RoomId\" : \"2471\" , \"DateTime\": \"2024-02-12 03:35:21\" , \"ImagePath\" : \"C:\\\\\\\\Users\\\\\\\\Moataz Nasr\\\\\\\\Downloads\\\\\\\\images\\\\\\\\image_9.jpg\"}'\n",
      "C:\\Users\\Moataz Nasr\\Downloads\\images\\image_9.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Moataz Nasr\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\PIL\\TiffImagePlugin.py:866: UserWarning: Corrupt EXIF data.  Expecting to read 2 bytes but only got 0. \n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 272ms/step\n",
      "Processed message: {'HomeId': '268', 'RoomId': '2471', 'DateTime': '2024-02-12 03:35:21', 'ImagePath': 'C:\\\\Users\\\\Moataz Nasr\\\\Downloads\\\\images\\\\image_9.jpg', 'probability': 1.0, 'class_name': 'non_fire_images'}\n",
      "Received message: b'{\"HomeId\" : \"268\" , \"RoomId\" : \"2471\" , \"DateTime\": \"2024-02-12 03:35:21\" , \"ImagePath\" : \"C:\\\\\\\\Users\\\\\\\\Moataz Nasr\\\\\\\\Downloads\\\\\\\\images\\\\\\\\image_7.jpg\"}'\n",
      "C:\\Users\\Moataz Nasr\\Downloads\\images\\image_7.jpg\n",
      "1/1 [==============================] - 0s 205ms/step\n",
      "Processed message: {'HomeId': '268', 'RoomId': '2471', 'DateTime': '2024-02-12 03:35:21', 'ImagePath': 'C:\\\\Users\\\\Moataz Nasr\\\\Downloads\\\\images\\\\image_7.jpg', 'probability': 1.0, 'class_name': 'non_fire_images'}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Consume messages from Kafka\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m message \u001b[38;5;129;01min\u001b[39;00m consumer:\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m      4\u001b[0m         \u001b[38;5;66;03m# Check if the message is empty\u001b[39;00m\n\u001b[0;32m      5\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m message\u001b[38;5;241m.\u001b[39mvalue:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\kafka\\consumer\\group.py:1193\u001b[0m, in \u001b[0;36mKafkaConsumer.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1191\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnext_v1()\n\u001b[0;32m   1192\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1193\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext_v2\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\kafka\\consumer\\group.py:1201\u001b[0m, in \u001b[0;36mKafkaConsumer.next_v2\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1199\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_message_generator_v2()\n\u001b[0;32m   1200\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1201\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator)\n\u001b[0;32m   1202\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m   1203\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\kafka\\consumer\\group.py:1116\u001b[0m, in \u001b[0;36mKafkaConsumer._message_generator_v2\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_message_generator_v2\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1115\u001b[0m     timeout_ms \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m \u001b[38;5;241m*\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_consumer_timeout \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mtime())\n\u001b[1;32m-> 1116\u001b[0m     record_map \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout_ms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdate_offsets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1117\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m tp, records \u001b[38;5;129;01min\u001b[39;00m six\u001b[38;5;241m.\u001b[39miteritems(record_map):\n\u001b[0;32m   1118\u001b[0m         \u001b[38;5;66;03m# Generators are stateful, and it is possible that the tp / records\u001b[39;00m\n\u001b[0;32m   1119\u001b[0m         \u001b[38;5;66;03m# here may become stale during iteration -- i.e., we seek to a\u001b[39;00m\n\u001b[0;32m   1120\u001b[0m         \u001b[38;5;66;03m# different offset, pause consumption, or lose assignment.\u001b[39;00m\n\u001b[0;32m   1121\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m record \u001b[38;5;129;01min\u001b[39;00m records:\n\u001b[0;32m   1122\u001b[0m             \u001b[38;5;66;03m# is_fetchable(tp) should handle assignment changes and offset\u001b[39;00m\n\u001b[0;32m   1123\u001b[0m             \u001b[38;5;66;03m# resets; for all other changes (e.g., seeks) we'll rely on the\u001b[39;00m\n\u001b[0;32m   1124\u001b[0m             \u001b[38;5;66;03m# outer function destroying the existing iterator/generator\u001b[39;00m\n\u001b[0;32m   1125\u001b[0m             \u001b[38;5;66;03m# via self._iterator = None\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\kafka\\consumer\\group.py:655\u001b[0m, in \u001b[0;36mKafkaConsumer.poll\u001b[1;34m(self, timeout_ms, max_records, update_offsets)\u001b[0m\n\u001b[0;32m    653\u001b[0m remaining \u001b[38;5;241m=\u001b[39m timeout_ms\n\u001b[0;32m    654\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 655\u001b[0m     records \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_records\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupdate_offsets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mupdate_offsets\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    656\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m records:\n\u001b[0;32m    657\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m records\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\kafka\\consumer\\group.py:702\u001b[0m, in \u001b[0;36mKafkaConsumer._poll_once\u001b[1;34m(self, timeout_ms, max_records, update_offsets)\u001b[0m\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_client\u001b[38;5;241m.\u001b[39mpoll(timeout_ms\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    701\u001b[0m timeout_ms \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(timeout_ms, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_coordinator\u001b[38;5;241m.\u001b[39mtime_to_next_poll() \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m)\n\u001b[1;32m--> 702\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout_ms\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;66;03m# after the long poll, we should check whether the group needs to rebalance\u001b[39;00m\n\u001b[0;32m    704\u001b[0m \u001b[38;5;66;03m# prior to returning data so that the group can stabilize faster\u001b[39;00m\n\u001b[0;32m    705\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_coordinator\u001b[38;5;241m.\u001b[39mneed_rejoin():\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\kafka\\client_async.py:602\u001b[0m, in \u001b[0;36mKafkaClient.poll\u001b[1;34m(self, timeout_ms, future)\u001b[0m\n\u001b[0;32m    599\u001b[0m             timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(timeout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mretry_backoff_ms\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m    600\u001b[0m         timeout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, timeout)  \u001b[38;5;66;03m# avoid negative timeouts\u001b[39;00m\n\u001b[1;32m--> 602\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    604\u001b[0m \u001b[38;5;66;03m# called without the lock to avoid deadlock potential\u001b[39;00m\n\u001b[0;32m    605\u001b[0m \u001b[38;5;66;03m# if handlers need to acquire locks\u001b[39;00m\n\u001b[0;32m    606\u001b[0m responses\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fire_pending_completed_requests())\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\kafka\\client_async.py:634\u001b[0m, in \u001b[0;36mKafkaClient._poll\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_register_send_sockets()\n\u001b[0;32m    633\u001b[0m start_select \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m--> 634\u001b[0m ready \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    635\u001b[0m end_select \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m    636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sensors:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\selectors.py:323\u001b[0m, in \u001b[0;36mSelectSelector.select\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    321\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 323\u001b[0m     r, w, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_select\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_readers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_writers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\selectors.py:314\u001b[0m, in \u001b[0;36mSelectSelector._select\u001b[1;34m(self, r, w, _, timeout)\u001b[0m\n\u001b[0;32m    313\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_select\u001b[39m(\u001b[38;5;28mself\u001b[39m, r, w, _, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 314\u001b[0m     r, w, x \u001b[38;5;241m=\u001b[39m select\u001b[38;5;241m.\u001b[39mselect(r, w, w, timeout)\n\u001b[0;32m    315\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m r, w \u001b[38;5;241m+\u001b[39m x, []\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Consume messages from Kafka\n",
    "for message in consumer:\n",
    "    try:\n",
    "        # Check if the message is empty\n",
    "        if not message.value:\n",
    "            print(\"Ignoring empty message.\")\n",
    "            continue\n",
    "\n",
    "        # Print the content of the message\n",
    "        print(\"Received message:\", message.value)\n",
    "\n",
    "        # Parse message as JSON\n",
    "        data_dict = json.loads(message.value.decode('utf-8'))\n",
    "\n",
    "        # Extract fields from the JSON\n",
    "        HomeId = data_dict['HomeId']\n",
    "        RoomId = data_dict['RoomId']\n",
    "        DateTime = data_dict['DateTime']\n",
    "        ImagePath = data_dict['ImagePath']\n",
    "        print(ImagePath)\n",
    "        # Read image from folder\n",
    "        image_path = os.path.join(data_dict['ImagePath'])\n",
    "        image = Image.open(image_path)\n",
    "\n",
    "        # Preprocess image for VGG16\n",
    "        image = image.resize((224, 224))\n",
    "        image = image.convert('RGB')\n",
    "        image_array = preprocess_input(np.array(image))\n",
    "        image_array = np.expand_dims(image_array, axis=0)\n",
    "\n",
    "        # Classify the image\n",
    "        prediction = save_model.predict(image_array)\n",
    "        class_index = np.where(prediction >= 0.5, 1, 0)[0][0]\n",
    "        class_name = class_names[class_index]\n",
    "        probability = float(prediction)\n",
    "       \n",
    "\n",
    "        session.execute(f\"INSERT INTO {cassandra_table} (id,homeId ,roomId, class_name, image_Path, DateTime) VALUES (uuid(),'{HomeId}' ,'{RoomId}', '{class_name}', '{image_path}', '{DateTime}')\")\n",
    "\n",
    "\n",
    "        # Publish data to another Kafka topic\n",
    "        data_dict['probability'] = probability\n",
    "        data_dict['class_name'] = class_name\n",
    "\n",
    "        # Convert the dictionary to JSON\n",
    "       # json_data = json.dumps(data_dict)\n",
    "\n",
    "        # Send the JSON data to the output topic\n",
    "       # producer.send(output_topic, value=json_data.encode('utf-8'))\n",
    "\n",
    "        print(\"Processed message:\", data_dict)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(\"Error processing message:\", e)\n",
    "\n",
    "# Close Kafka producer and consumer\n",
    "producer.close()\n",
    "consumer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe940eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4749fda9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b077b599",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
